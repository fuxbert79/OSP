"""
OSP Multi-Layer RAG Pipeline mit Kontakt-Lookup
===============================================

Erweiterte Pipeline mit JSON-basiertem Kontakt-Lookup
fÃ¼r sofortige Antworten bei Werkzeug-Anfragen.

Embedding-Modell: intfloat/multilingual-e5-large (1024 dim)
WICHTIG: E5-Modelle erfordern PrÃ¤fixe:
- "passage: " fÃ¼r Dokumente (beim Indizieren)
- "query: " fÃ¼r Suchanfragen

Autor: AL
Stand: 2025-12-14
Deployment: /mnt/HC_Volume_104189729/osp/pipelines/osp_rag.py

Architektur:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           USER MESSAGE                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: KONTAKT-LOOKUP (PRE-RAG)       â”‚
â”‚  Pattern: \\d-\\d{6,7}-\\d               â”‚
â”‚  â†’ Bei Treffer: Direkte Antwort         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ Kein Match
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: RAG-VERARBEITUNG (E5-large)    â”‚
â”‚  â†’ ChromaDB Query â†’ LLM Response        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import logging
import os
import sys
from pathlib import Path
from typing import Union, Generator, Iterator, List, Optional

from pydantic import BaseModel, Field

# Logging konfigurieren
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Modul-Pfad hinzufÃ¼gen fÃ¼r Lookup-Import
sys.path.insert(0, str(Path(__file__).parent / 'modules'))

try:
    from kontakt_lookup import check_kontakt_lookup, get_lookup_stats, reload_lookup_cache
    LOOKUP_AVAILABLE = True
except ImportError as e:
    logger.warning(f"âš ï¸ Kontakt-Lookup Modul nicht verfÃ¼gbar: {e}")
    LOOKUP_AVAILABLE = False

    # Fallback-Funktionen
    def check_kontakt_lookup(msg): return None
    def get_lookup_stats(): return {"verfÃ¼gbar": False}
    def reload_lookup_cache(): return False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KEYWORD-FILTER (PRE-RAG)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from keyword_filter import (
        check_keyword_trigger,
        get_filter_stats,
        reload_filter,
        get_keyword_filter
    )
    KEYWORD_FILTER_AVAILABLE = True
    logger.info("âœ… Keyword-Filter Modul geladen")
except ImportError as e:
    logger.warning(f"âš ï¸ Keyword-Filter Modul nicht verfÃ¼gbar: {e}")
    KEYWORD_FILTER_AVAILABLE = False

    # Fallback-Funktionen
    def check_keyword_trigger(query, path=None): return None
    def get_filter_stats(): return {"verfÃ¼gbar": False}
    def reload_filter(path=None): return {"verfÃ¼gbar": False}
    def get_keyword_filter(path=None): return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MA-KÃœRZEL PREPROCESSING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from ma_preprocessing import expand_ma_query, get_preprocessor
    MA_PREPROCESSING_AVAILABLE = True
    logger.info("âœ… MA-Preprocessing Modul geladen")
except ImportError as e:
    logger.warning(f"âš ï¸ MA-Preprocessing Modul nicht verfÃ¼gbar: {e}")
    MA_PREPROCESSING_AVAILABLE = False

    # Fallback-Funktion
    def expand_ma_query(query, json_path=None):
        return query

    def get_preprocessor(json_path=None):
        return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# QUERY-NORMALISIERUNG
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from query_normalizer import normalize_query, get_normalizer
    QUERY_NORMALIZER_AVAILABLE = True
    logger.info("âœ… Query-Normalizer Modul geladen")
except ImportError as e:
    logger.warning(f"âš ï¸ Query-Normalizer nicht verfÃ¼gbar: {e}")
    QUERY_NORMALIZER_AVAILABLE = False

    def normalize_query(query, path=None):
        return query

    def get_normalizer(path=None):
        return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAG-ROUTER (ChromaDB WHERE-Filter)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from tag_router import get_tag_router, extract_tags, get_where_filter
    TAG_ROUTER_AVAILABLE = True
    logger.info("âœ… Tag-Router Modul geladen")
except ImportError as e:
    logger.warning(f"âš ï¸ Tag-Router nicht verfÃ¼gbar: {e}")
    TAG_ROUTER_AVAILABLE = False

    def extract_tags(query): return []
    def get_where_filter(query): return None
    def get_tag_router(): return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WARTUNGS-LOOKUP (WIM/WIW/Form-Schemas)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from wartungs_lookup import (
        get_wartungs_lookup,
        check_wartungs_lookup,
        get_form_schema_for_query,
        get_wartungs_stats,
        reload_wartungs_lookup
    )
    WARTUNGS_LOOKUP_AVAILABLE = True
    logger.info("âœ… Wartungs-Lookup Modul geladen")
except ImportError as e:
    logger.warning(f"âš ï¸ Wartungs-Lookup nicht verfÃ¼gbar: {e}")
    WARTUNGS_LOOKUP_AVAILABLE = False

    def check_wartungs_lookup(query): return None
    def get_form_schema_for_query(query): return None
    def get_wartungs_stats(): return {"verfÃ¼gbar": False}
    def reload_wartungs_lookup(): return False
    def get_wartungs_lookup(path=None): return None


class Valves(BaseModel):
    """Pipeline-Konfigurationsparameter (kÃ¶nnen in WebUI geÃ¤ndert werden)"""
    ANTHROPIC_API_KEY: str = Field(
        default_factory=lambda: os.getenv("ANTHROPIC_API_KEY", ""),
        description="Anthropic API Key"
    )
    CHROMADB_HOST: str = Field(default="chromadb", description="ChromaDB Host")
    CHROMADB_PORT: int = Field(default=8000, description="ChromaDB Port")
    ENABLE_LOGGING: bool = Field(default=True, description="Logging aktivieren")
    ENABLE_LOOKUP: bool = Field(default=True, description="Kontakt-Lookup aktivieren")
    ENABLE_KEYWORD_FILTER: bool = Field(default=True, description="Keyword-Trigger Pre-RAG Filter aktivieren")
    ENABLE_MA_PREPROCESSING: bool = Field(default=True, description="MA-KÃ¼rzel Query-Expansion aktivieren")
    ENABLE_QUERY_NORMALIZATION: bool = Field(default=True, description="Query-Normalisierung (Tippfehler, Case) aktivieren")
    ENABLE_TAG_ROUTING: bool = Field(default=True, description="Tag-basiertes ChromaDB WHERE-Filter Routing")
    ENABLE_WARTUNGS_LOOKUP: bool = Field(default=True, description="Wartungs-Lookup (WIM/WIW/Form-Schemas) aktivieren")
    MA_KUERZEL_PATH: str = Field(default="/app/backend/data/lookups/ma_kuerzel.json", description="Pfad zur MA-KÃ¼rzel JSON")
    LOOKUPS_PATH: str = Field(default="/app/backend/data/lookups", description="Pfad zum Lookups-Verzeichnis")
    DOCUMENTS_PATH: str = Field(default="/app/backend/data/docs", description="Pfad zum Documents-Verzeichnis")
    MAX_CONTEXT_LENGTH: int = Field(default=16000, description="Max Context-LÃ¤nge")
    USE_STREAMING: bool = Field(default=True, description="Streaming aktivieren")
    TOP_K: int = Field(default=15, description="Anzahl der RAG-Ergebnisse")


class Pipeline:
    """
    OSP Multi-Layer RAG Pipeline fÃ¼r Schneider Kabelsatzbau.
    
    Features:
    - Kontakt-WKZ Lookup (JSON-basiert, vor RAG)
    - Multi-Layer RAG (KERN â†’ KPL â†’ ERWEITERT)
    - Streaming Support
    - Confidence-Level Tracking
    
    Attributes:
        name: Pipeline-Name fÃ¼r WebUI
        id: Eindeutige Pipeline-ID
        valves: Konfigurationsparameter
    """
    
    def __init__(self):
        """
        Initialize Pipeline.

        âš ï¸ WICHTIG: Keine schweren Operationen hier!
        Nutze on_startup() fÃ¼r Resource-Loading.
        """
        self.name = "OSP Multi-Layer RAG"
        self.id = "osp_rag"

        # Pydantic-Valves (kÃ¶nnen in WebUI geÃ¤ndert werden)
        self.valves = Valves()

        # Lazy-loaded Resources
        self.router = None
        self.llm_client = None
        self.chroma_client = None
        self.lookup_stats = None
        self.embedding_model = None  # E5-large fÃ¼r Query-Embeddings
        self.ma_preprocessor = None  # MA-KÃ¼rzel Preprocessing
        self.keyword_filter = None   # Keyword-Trigger Pre-RAG Filter
        self.keyword_filter_stats = None
        self.query_normalizer = None  # Query-Normalisierung (Tippfehler)
        self.tag_router = None        # Tag-basiertes ChromaDB Routing
        self.wartungs_lookup = None   # WIM/WIW/Form-Schema Lookup
        self.wartungs_lookup_stats = None

    async def on_startup(self):
        """
        Asynchron lifecycle hook - wird EINMAL beim Container-Start aufgerufen.
        
        Initialisiert:
        - Kontakt-Lookup System
        - ChromaDB Verbindung
        - LLM Client
        """
        logger.info("ğŸš€ OSP RAG Pipeline Starting...")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # LOOKUP-SYSTEM INITIALISIEREN
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if LOOKUP_AVAILABLE and self.valves.ENABLE_LOOKUP:
            self.lookup_stats = get_lookup_stats()
            if self.lookup_stats.get('verfÃ¼gbar'):
                logger.info(
                    f"âœ… Kontakt-Lookup aktiv: "
                    f"{self.lookup_stats['eintraege']} EintrÃ¤ge "
                    f"(Stand: {self.lookup_stats['stand']})"
                )
            else:
                logger.warning("âš ï¸ Kontakt-Lookup nicht verfÃ¼gbar - nur RAG-Modus")
        else:
            logger.info("â„¹ï¸ Kontakt-Lookup deaktiviert")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # MA-KÃœRZEL PREPROCESSING INITIALISIEREN
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if MA_PREPROCESSING_AVAILABLE and self.valves.ENABLE_MA_PREPROCESSING:
            try:
                self.ma_preprocessor = get_preprocessor(self.valves.MA_KUERZEL_PATH)
                if self.ma_preprocessor and self.ma_preprocessor._loaded:
                    logger.info(
                        f"âœ… MA-Preprocessing aktiv: "
                        f"{len(self.ma_preprocessor.kuerzel_set)} KÃ¼rzel, "
                        f"{len(self.ma_preprocessor.patterns)} Patterns"
                    )
                else:
                    logger.warning("âš ï¸ MA-Preprocessing konnte nicht initialisiert werden")
            except Exception as e:
                logger.error(f"âŒ MA-Preprocessing Fehler: {e}")
                self.ma_preprocessor = None
        else:
            logger.info("â„¹ï¸ MA-Preprocessing deaktiviert")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # QUERY-NORMALIZER INITIALISIEREN
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if QUERY_NORMALIZER_AVAILABLE and self.valves.ENABLE_QUERY_NORMALIZATION:
            try:
                self.query_normalizer = get_normalizer()
                stats = self.query_normalizer.get_stats()
                if stats.get('verfÃ¼gbar'):
                    logger.info(
                        f"âœ… Query-Normalizer aktiv: "
                        f"{stats['corrections_count']} Korrekturen"
                    )
                else:
                    logger.warning("âš ï¸ Query-Normalizer: Keine Korrekturen geladen")
            except Exception as e:
                logger.error(f"âŒ Query-Normalizer Fehler: {e}")
                self.query_normalizer = None
        else:
            logger.info("â„¹ï¸ Query-Normalizer deaktiviert")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # KEYWORD-FILTER INITIALISIEREN (PRE-RAG)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if KEYWORD_FILTER_AVAILABLE and self.valves.ENABLE_KEYWORD_FILTER:
            try:
                self.keyword_filter = get_keyword_filter(Path(self.valves.DOCUMENTS_PATH))
                self.keyword_filter_stats = self.keyword_filter.get_stats()
                if self.keyword_filter_stats.get('verfÃ¼gbar'):
                    logger.info(
                        f"âœ… Keyword-Filter aktiv: "
                        f"{self.keyword_filter_stats['patterns_count']} Patterns, "
                        f"Pfad: {self.keyword_filter_stats['documents_path']}"
                    )
                else:
                    logger.warning("âš ï¸ Keyword-Filter initialisiert aber Dokumente nicht verfÃ¼gbar")
            except Exception as e:
                logger.error(f"âŒ Keyword-Filter Fehler: {e}")
                self.keyword_filter = None
                self.keyword_filter_stats = {"verfÃ¼gbar": False, "error": str(e)}
        else:
            logger.info("â„¹ï¸ Keyword-Filter deaktiviert")
            self.keyword_filter_stats = {"verfÃ¼gbar": False, "reason": "deaktiviert"}

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # TAG-ROUTER INITIALISIEREN (ChromaDB WHERE-Filter)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if TAG_ROUTER_AVAILABLE and self.valves.ENABLE_TAG_ROUTING:
            try:
                self.tag_router = get_tag_router()
                logger.info(f"âœ… Tag-Router aktiv: {len(self.tag_router.compiled_patterns)} TAGs")
            except Exception as e:
                logger.error(f"âŒ Tag-Router Fehler: {e}")
                self.tag_router = None
        else:
            logger.info("â„¹ï¸ Tag-Router deaktiviert")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # WARTUNGS-LOOKUP INITIALISIEREN (WIM/WIW/Form-Schemas)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if WARTUNGS_LOOKUP_AVAILABLE and self.valves.ENABLE_WARTUNGS_LOOKUP:
            try:
                self.wartungs_lookup = get_wartungs_lookup(Path(self.valves.LOOKUPS_PATH))
                self.wartungs_lookup_stats = get_wartungs_stats()
                if self.wartungs_lookup_stats.get('verfÃ¼gbar'):
                    logger.info(
                        f"âœ… Wartungs-Lookup aktiv: "
                        f"WIM={self.wartungs_lookup_stats['wim']['maschinen']} Maschinen, "
                        f"WIW={self.wartungs_lookup_stats['wiw']['werkzeuge']} Werkzeuge, "
                        f"Forms={self.wartungs_lookup_stats['forms']['formulare']} Formulare"
                    )
                else:
                    logger.warning("âš ï¸ Wartungs-Lookup: Daten nicht vollstÃ¤ndig geladen")
            except Exception as e:
                logger.error(f"âŒ Wartungs-Lookup Fehler: {e}")
                self.wartungs_lookup = None
                self.wartungs_lookup_stats = {"verfÃ¼gbar": False, "error": str(e)}
        else:
            logger.info("â„¹ï¸ Wartungs-Lookup deaktiviert")
            self.wartungs_lookup_stats = {"verfÃ¼gbar": False, "reason": "deaktiviert"}

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # E5-LARGE EMBEDDING-MODELL LADEN
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            from sentence_transformers import SentenceTransformer

            logger.info("ğŸ“¥ Lade E5-large Embedding-Modell...")
            self.embedding_model = SentenceTransformer(
                'intfloat/multilingual-e5-large',
                device='cpu'
            )
            logger.info(f"âœ… E5-large geladen (Dimension: {self.embedding_model.get_sentence_embedding_dimension()})")

        except Exception as e:
            logger.error(f"âŒ E5-large Modell konnte nicht geladen werden: {e}")
            self.embedding_model = None

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # CHROMADB INITIALISIEREN
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            import chromadb
            from chromadb.config import Settings

            self.chroma_client = chromadb.HttpClient(
                host=self.valves.CHROMADB_HOST,
                port=self.valves.CHROMADB_PORT,
                settings=Settings(anonymized_telemetry=False)
            )

            # Verbindung testen
            collections = self.chroma_client.list_collections()
            logger.info(f"âœ… ChromaDB verbunden: {len(collections)} Collections")

        except Exception as e:
            logger.error(f"âŒ ChromaDB Verbindung fehlgeschlagen: {e}")
            self.chroma_client = None
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # LLM CLIENT INITIALISIEREN
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            from anthropic import Anthropic
            
            api_key = self.valves.ANTHROPIC_API_KEY
            if api_key:
                self.llm_client = Anthropic(api_key=api_key)
                logger.info("âœ… Anthropic Client initialisiert")
            else:
                logger.warning("âš ï¸ ANTHROPIC_API_KEY nicht gesetzt")
                
        except ImportError:
            logger.warning("âš ï¸ Anthropic SDK nicht installiert")
        except Exception as e:
            logger.error(f"âŒ LLM Client Fehler: {e}")
        
        logger.info("âœ… OSP RAG Pipeline Ready")
    
    async def on_shutdown(self):
        """
        Lifecycle hook - wird beim Container-Shutdown aufgerufen.
        Cleanup fÃ¼r Ressourcen.
        """
        logger.info("ğŸ›‘ OSP RAG Pipeline Shutdown...")
        
        # ChromaDB Verbindung schlieÃŸen (falls nÃ¶tig)
        if self.chroma_client:
            try:
                # HttpClient hat kein explizites close()
                pass
            except Exception as e:
                logger.error(f"Shutdown Error: {e}")
        
        logger.info("âœ… OSP RAG Pipeline gestoppt")
    
    def pipe(
        self,
        user_message: str,
        model_id: str,
        messages: List[dict],
        body: dict,
    ) -> Union[str, Generator, Iterator]:
        """
        Main Processing Method mit Lookup-First-Strategie.
        
        Ablauf:
        1. Kontakt-Lookup prÃ¼fen (schnell, deterministisch)
        2. Falls Treffer: Direkte Antwort zurÃ¼ckgeben
        3. Falls kein Treffer: Normale RAG-Verarbeitung
        
        Parameters:
            user_message: Die aktuelle User-Eingabe
            model_id: Das ausgewÃ¤hlte Modell-ID in WebUI
            messages: Komplette Chat-History
            body: ZusÃ¤tzliche Parameter (OpenAI-compatible)
        
        Returns:
            str oder Generator mit der Antwort
        """

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP -1: QUERY-NORMALISIERUNG (Tippfehler, Case)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if QUERY_NORMALIZER_AVAILABLE and self.valves.ENABLE_QUERY_NORMALIZATION:
            normalized = normalize_query(user_message)
            if normalized != user_message.lower():
                logger.info(f"ğŸ“ Query normalisiert: '{user_message}' â†’ '{normalized}'")
                user_message = normalized

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 0: MA-KÃœRZEL QUERY-EXPANSION
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        original_query = user_message
        if MA_PREPROCESSING_AVAILABLE and self.valves.ENABLE_MA_PREPROCESSING:
            expanded_query = expand_ma_query(user_message, self.valves.MA_KUERZEL_PATH)
            if expanded_query != user_message:
                logger.info(f"ğŸ”„ MA-Expansion: '{user_message}' â†’ '{expanded_query[:80]}...'")
                user_message = expanded_query

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 1: KONTAKT-LOOKUP (VOR RAG!) - verwendet Original-Query
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if LOOKUP_AVAILABLE and self.valves.ENABLE_LOOKUP:
            lookup_result = check_kontakt_lookup(original_query)

            if lookup_result is not None:
                # Treffer! Direkte Antwort ohne RAG
                logger.info("ğŸ“¦ Kontakt-Lookup Treffer - Direkte Antwort")
                return lookup_result

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 1.3: WARTUNGS-LOOKUP (WIM/WIW) - PRE-RAG
        # Wartungsanfragen fÃ¼r Maschinen/Werkzeuge mit direkter Antwort
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if WARTUNGS_LOOKUP_AVAILABLE and self.valves.ENABLE_WARTUNGS_LOOKUP:
            wartungs_result = check_wartungs_lookup(original_query)

            if wartungs_result is not None:
                # Treffer! Direkte Antwort mit Wartungsdaten/PDFs
                logger.info("ğŸ”§ Wartungs-Lookup Treffer - Direkte Antwort")
                return wartungs_result

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 1.5: KEYWORD-FILTER (PRE-RAG)
        # Kritische Keywords triggern direktes Laden des Zieldokuments
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        keyword_context = None
        if KEYWORD_FILTER_AVAILABLE and self.valves.ENABLE_KEYWORD_FILTER and self.keyword_filter:
            keyword_result = self.keyword_filter.get_triggered_context(user_message)

            if keyword_result:
                # Keyword-Trigger! Dokument direkt als Kontext verwenden
                logger.info(
                    f"ğŸ¯ Keyword-Trigger: '{keyword_result['trigger']}' â†’ "
                    f"{keyword_result['filename']} (P{keyword_result['priority']})"
                )
                keyword_context = keyword_result

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 2: NORMALE RAG-VERARBEITUNG (oder Keyword-Context nutzen)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info("ğŸ” Starte RAG-Verarbeitung...")
        
        # PrÃ¼fen ob RAG verfÃ¼gbar
        if not self.chroma_client:
            return self._error_response(
                "ChromaDB nicht verfÃ¼gbar. Bitte Administrator kontaktieren."
            )
        
        if not self.llm_client:
            return self._error_response(
                "LLM nicht verfÃ¼gbar. Bitte API-Key prÃ¼fen."
            )
        
        try:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # 2.1 Context zusammenstellen
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            context_parts = []

            # 2.1a KEYWORD-TRIGGER KONTEXT (hÃ¶chste PrioritÃ¤t)
            if keyword_context:
                keyword_doc = keyword_context['document']
                keyword_file = keyword_context['filename']
                keyword_trigger = keyword_context['trigger']

                # Truncate wenn zu lang
                max_keyword_len = self.valves.MAX_CONTEXT_LENGTH // 2
                if len(keyword_doc) > max_keyword_len:
                    keyword_doc = keyword_doc[:max_keyword_len] + "\n...[TRUNCATED]..."

                context_parts.append(
                    f"[PRIORITÃ„T: KEYWORD-TRIGGER '{keyword_trigger}']\n"
                    f"[Quelle: {keyword_file} | Score: 1.00 (direkt)]\n{keyword_doc}"
                )
                logger.info(f"ğŸ“„ Keyword-Context: {keyword_file} ({len(keyword_doc)} Zeichen)")

            # 2.1b RAG KONTEXT (ergÃ¤nzend)
            rag_context = self._retrieve_context(user_message)

            if rag_context:
                # Wenn Keyword-Context vorhanden, reduziere RAG-Context-LÃ¤nge
                if keyword_context:
                    remaining_len = self.valves.MAX_CONTEXT_LENGTH - len(context_parts[0])
                    if len(rag_context) > remaining_len:
                        rag_context = rag_context[:remaining_len] + "\n...[TRUNCATED]..."
                context_parts.append(rag_context)
            elif not keyword_context:
                logger.warning("âš ï¸ Kein relevanter Kontext gefunden")
                context_parts.append("Keine relevanten Dokumente gefunden.")

            # Finaler Context
            context = "\n\n" + "â•" * 50 + "\n\n".join(context_parts)

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # 2.2 LLM Response generieren
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            response = self._generate_response(
                user_message=user_message,
                context=context,
                messages=messages,
                body=body
            )

            return response

        except Exception as e:
            logger.error(f"RAG-Fehler: {e}")
            return self._error_response(str(e))
    
    def _retrieve_context(self, query: str) -> str:
        """
        Ruft relevanten Kontext aus ChromaDB ab.

        Multi-Layer Strategie:
        1. OSP_KERN (PrioritÃ¤t 1)
        2. OSP_KPL (PrioritÃ¤t 2)
        3. OSP_ERWEITERT (PrioritÃ¤t 3)

        WICHTIG: E5-Modelle erfordern "query: " PrÃ¤fix fÃ¼r Suchanfragen!
        """
        try:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # E5-QUERY EMBEDDING BERECHNEN
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if self.embedding_model is None:
                logger.error("âŒ E5-Embedding-Modell nicht verfÃ¼gbar!")
                return ""

            # E5-Modelle erfordern "query: " PrÃ¤fix fÃ¼r Suchanfragen
            query_with_prefix = f"query: {query}"
            query_embedding = self.embedding_model.encode(
                [query_with_prefix],
                normalize_embeddings=True
            ).tolist()

            logger.debug(f"Query-Embedding berechnet fÃ¼r: '{query[:50]}...'")

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # MULTI-LAYER SUCHE
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            collections_priority = [
                "osp_kern",
                "osp_kpl",
                "osp_erweitert"
            ]

            all_results = []
            top_k = self.valves.TOP_K

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # TAG-FILTER FÃœR CHROMADB (nur fÃ¼r osp_kern Collection)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            where_filter = None
            if self.tag_router and self.valves.ENABLE_TAG_ROUTING:
                where_filter = get_where_filter(query)
                if where_filter:
                    logger.info(f"ğŸ·ï¸ Tag-Filter: {where_filter}")

            for collection_name in collections_priority:
                try:
                    collection = self.chroma_client.get_collection(collection_name)

                    # TAG-Filter nur fÃ¼r osp_kern verwenden
                    current_where = where_filter if collection_name == "osp_kern" else None

                    # Verwende query_embeddings statt query_texts fÃ¼r E5
                    results = collection.query(
                        query_embeddings=query_embedding,
                        n_results=top_k,
                        where=current_where,
                        include=["documents", "metadatas", "distances"]
                    )

                    num_ids = len(results.get('ids', [[]])[0])
                    has_docs = bool(results.get('documents') and results['documents'][0])
                    logger.info(f"  {collection_name}: {num_ids} IDs, docs={has_docs}")

                    if results and results.get('documents') and results['documents'][0]:
                        for doc, meta, dist in zip(
                            results['documents'][0],
                            results['metadatas'][0],
                            results['distances'][0]
                        ):
                            all_results.append({
                                'document': doc,
                                'metadata': meta,
                                'distance': dist,
                                'source': collection_name,
                                'filename': meta.get('filename', 'unbekannt')
                            })

                except Exception as e:
                    logger.warning(f"Collection {collection_name} nicht verfÃ¼gbar: {e}")
                    continue

            logger.info(f"  Gesamt all_results: {len(all_results)}")

            # Nach Distanz sortieren (niedrigste = beste Ãœbereinstimmung)
            all_results.sort(key=lambda x: x['distance'])

            # Top-Ergebnisse fÃ¼r Kontext zusammenstellen
            context_parts = []
            max_length = self.valves.MAX_CONTEXT_LENGTH
            current_length = 0

            logger.debug(f"  Baue Kontext aus {len(all_results)} Ergebnissen (max_length={max_length})")

            for result in all_results[:top_k]:
                doc = result['document']
                filename = result['filename']
                score = 1 - result['distance']  # Cosine similarity

                if doc is None or len(doc) == 0:
                    continue
                if current_length + len(doc) > max_length:
                    if current_length == 0:
                        # Erstes Dokument ist zu groÃŸ - truncate
                        truncated = doc[:max_length - 200] + "\n...[TRUNCATED]..."
                        context_parts.append(f"[Quelle: {filename} | Score: {score:.2f}]\n{truncated}")
                        current_length = len(truncated)
                    break

                context_parts.append(f"[Quelle: {filename} | Score: {score:.2f}]\n{doc}")
                current_length += len(doc)

            logger.info(f"ğŸ“š {len(context_parts)} KontextblÃ¶cke ({current_length} Zeichen)")

            return "\n\n---\n\n".join(context_parts)

        except Exception as e:
            logger.error(f"Context Retrieval Error: {e}")
            return ""
    
    def _generate_response(
        self,
        user_message: str,
        context: str,
        messages: List[dict],
        body: dict
    ) -> str:
        """
        Generiert LLM Response mit Kontext.
        """
        system_prompt = """Du bist der OSP-Assistent fÃ¼r Rainer Schneider Kabelsatzbau GmbH & Co. KG.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ NULL-FEHLER-POLITIK (ABSOLUT VERBINDLICH!)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. NIEMALS Informationen erfinden - bei Unsicherheit NACHFRAGEN
2. KEINE erfundenen MA-KÃ¼rzel - nur aus HR_CORE_Personalstamm.md
3. KEINE Phantasie-Daten bei Crimp/Werkzeug-Anfragen - VERIFIZIEREN
4. Confidence-Level (C: XX%) bei JEDER Faktenaussage PFLICHT
5. Bei WidersprÃ¼chen: TRANSPARENT melden, nicht verschweigen

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MA-KÃœRZEL SYSTEM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Mitarbeiter werden mit 2-3 Buchstaben-KÃ¼rzeln identifiziert.
Quelle: HR_CORE_Personalstamm.md (OSP_KERN)

SCHLÃœSSELPERSONEN:
- AL = Andreas LÃ¶hr (QM-Manager & KI-Manager, L3, OSP-EXP)
- CS = KaufmÃ¤nnischer GeschÃ¤ftsfÃ¼hrer (L3)
- CA = Technischer GeschÃ¤ftsfÃ¼hrer (L3)
- SV = Prokurist (L3)
- MD = Technik/Maschinen (L2)

Bei Fragen wie "Wer ist [KÃœRZEL]?" oder "Was macht [KÃœRZEL]?":
â†’ Suche im HR_CORE_Personalstamm.md
â†’ Gib Name, Funktion, Abteilung, ggf. Kontakt an
â†’ Bei unbekanntem KÃ¼rzel: "KÃ¼rzel nicht im Personalstamm gefunden"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ANTWORT-FORMAT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Antworte NUR basierend auf dem bereitgestellten Kontext
2. Strukturiere Antworten klar (Bullet Points, Tabellen wenn sinnvoll)
3. Zitiere die Quelle: [Quelle: Dateiname]
4. Confidence-Level am Ende: (C: XX%)
5. Kennzeichne mit [OSP] am Schluss

CONFIDENCE-SKALA:
- C: 90-100% = Direkt aus Kontext, eindeutig
- C: 70-89%  = Aus Kontext ableitbar, hohe Sicherheit
- C: 50-69%  = Teilweise im Kontext, Interpretation nÃ¶tig
- C: <50%    = Unzureichender Kontext â†’ NACHFRAGEN!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
KONTEXT (aus ChromaDB RAG)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{context}
""".format(context=context)
        
        try:
            response = self.llm_client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=body.get("max_tokens", 2000),
                system=system_prompt,
                messages=[{"role": "user", "content": user_message}]
            )
            
            return response.content[0].text
            
        except Exception as e:
            logger.error(f"LLM Generation Error: {e}")
            raise
    
    def _error_response(self, error_msg: str) -> str:
        """
        Formatiert eine Fehler-Antwort im OSP-Standard.
        """
        return f"""âŒ **Fehler bei der Verarbeitung**

{error_msg}

**MÃ¶gliche LÃ¶sungen:**
1. Anfrage neu formulieren
2. Administrator kontaktieren (AL)

(C: 0%) [OSP-Error]"""
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # UTILITY METHODS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def reload_lookup(self) -> dict:
        """
        LÃ¤dt die Lookup-Daten neu (nach JSON-Update).
        Kann Ã¼ber API aufgerufen werden.
        """
        if LOOKUP_AVAILABLE:
            success = reload_lookup_cache()
            self.lookup_stats = get_lookup_stats()
            return {
                "success": success,
                "stats": self.lookup_stats
            }
        return {"success": False, "reason": "Lookup nicht verfÃ¼gbar"}
    
    def get_status(self) -> dict:
        """
        Gibt den aktuellen Pipeline-Status zurÃ¼ck.
        """
        ma_status = {"verfÃ¼gbar": False}
        if self.ma_preprocessor and self.ma_preprocessor._loaded:
            ma_status = {
                "verfÃ¼gbar": True,
                "kuerzel_count": len(self.ma_preprocessor.kuerzel_set),
                "patterns_count": len(self.ma_preprocessor.patterns)
            }

        return {
            "name": self.name,
            "id": self.id,
            "lookup": self.lookup_stats or {"verfÃ¼gbar": False},
            "keyword_filter": self.keyword_filter_stats or {"verfÃ¼gbar": False},
            "wartungs_lookup": self.wartungs_lookup_stats or {"verfÃ¼gbar": False},
            "ma_preprocessing": ma_status,
            "chromadb": self.chroma_client is not None,
            "llm": self.llm_client is not None,
            "embedding_model": "intfloat/multilingual-e5-large" if self.embedding_model else None,
            "embedding_dim": self.embedding_model.get_sentence_embedding_dimension() if self.embedding_model else 0
        }

    def reload_keyword_filter(self) -> dict:
        """
        LÃ¤dt den Keyword-Filter neu (nach Pattern-Ã„nderungen).
        Kann Ã¼ber API aufgerufen werden.
        """
        if KEYWORD_FILTER_AVAILABLE:
            self.keyword_filter_stats = reload_filter(Path(self.valves.DOCUMENTS_PATH))
            self.keyword_filter = get_keyword_filter(Path(self.valves.DOCUMENTS_PATH))
            return {
                "success": True,
                "stats": self.keyword_filter_stats
            }
        return {"success": False, "reason": "Keyword-Filter nicht verfÃ¼gbar"}

    def reload_wartungs_lookup(self) -> dict:
        """
        LÃ¤dt den Wartungs-Lookup neu (nach JSON-Updates).
        Kann Ã¼ber API aufgerufen werden.
        """
        if WARTUNGS_LOOKUP_AVAILABLE:
            success = reload_wartungs_lookup()
            self.wartungs_lookup_stats = get_wartungs_stats()
            return {
                "success": success,
                "stats": self.wartungs_lookup_stats
            }
        return {"success": False, "reason": "Wartungs-Lookup nicht verfÃ¼gbar"}


# Pipeline-Instanz fÃ¼r Open WebUI
pipeline = Pipeline()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STANDALONE TEST
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    import asyncio
    
    async def test():
        print("=== OSP RAG Pipeline Test ===\n")
        
        # Startup
        await pipeline.on_startup()
        
        # Status
        print(f"Status: {pipeline.get_status()}\n")
        
        # Test-Anfragen
        test_queries = [
            "Welches WKZ fÃ¼r 0-0350415-1?",  # Lookup
            "Zeige mir den Komax Alpha 530",  # RAG
        ]
        
        for query in test_queries:
            print(f"Query: {query}")
            result = pipeline.pipe(query, "osp_rag", [], {})
            print(f"Result:\n{result}\n")
            print("-" * 50)
        
        # Shutdown
        await pipeline.on_shutdown()
    
    asyncio.run(test())
